{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameWidth = 640\n",
    "frameHeight = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.resize(img,(frameWidth,frameHeight))\n",
    "    cv2.imshow('Video',img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '346-3460443_machine-learning-course-near-me-machine-learning-logo.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path)\n",
    "imgGrey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGrey,(9,9),0)\n",
    "imgCanny = cv2.Canny(imgBlur,100,100)\n",
    "img\n",
    "cv2.imshow('Image',img)\n",
    "cv2.imshow('Image Grey',imgGrey)\n",
    "cv2.imshow('Image Blur',imgBlur)\n",
    "cv2.imshow('Image Canny',imgCanny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path)\n",
    "imgGrey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGrey,(9,9),0)\n",
    "imgCanny = cv2.Canny(imgBlur,100,100)\n",
    "imgDialation = cv2.dilate(imgCanny,kernel,iterations=1)\n",
    "imgErode = cv2.erode(imgDialation,kernel,iterations=1)\n",
    "img\n",
    "cv2.imshow('Image',img)\n",
    "cv2.imshow('Image Grey',imgGrey)\n",
    "cv2.imshow('Image Blur',imgBlur)\n",
    "cv2.imshow('Image Canny',imgCanny)\n",
    "cv2.imshow('Image Dialation',imgDialation)\n",
    "cv2.imshow('Image Erode',imgErode)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472, 630, 3)\n",
      "(500, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image.jpg')\n",
    "print(img.shape)\n",
    "width = 200\n",
    "height= 500\n",
    "imgResize = cv2.resize(img,(width,height))\n",
    "print(imgResize.shape)\n",
    "cv2.imshow('Image',img)\n",
    "cv2.imshow('Image Resize',imgResize)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69,  33,  25],\n",
       "       [ 70,  34,  26],\n",
       "       [ 71,  35,  27],\n",
       "       ...,\n",
       "       [163, 195, 164],\n",
       "       [163, 195, 164],\n",
       "       [164, 196, 165]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472, 630, 3)\n",
      "(500, 200, 3)\n",
      "(272, 430, 3)\n",
      "(472, 630, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image.jpg')\n",
    "print(img.shape)\n",
    "width = 200\n",
    "height= 500\n",
    "imgResize = cv2.resize(img,(width,height))\n",
    "print(imgResize.shape)\n",
    "imgCropped = img[200:472,100:530]\n",
    "print(imgCropped.shape)\n",
    "imgCroppedResized = cv2.resize(imgCropped,(img.shape[1],img.shape[0]))\n",
    "print(imgCroppedResized.shape)\n",
    "cv2.imshow('Image',img)\n",
    "cv2.imshow('Image Resize',imgResize)\n",
    "cv2.imshow('Image Cropped',imgCropped)\n",
    "cv2.imshow('Image Cropped Resized',imgCroppedResized)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512,512,3),np.uint8)\n",
    "print(img.shape)\n",
    "print(img)\n",
    "\n",
    "# It is representing the BGR channel. If we take img[:] then we're allowing to apply the BGR on full image.\n",
    "#If we define the height and width then it will apply on particular area like img[50:60,80:120] = 255,0,0\n",
    "img[:] = 255,0,0\n",
    "\n",
    "# How to create line on an image\n",
    "#cv2.line(img,(0,0),(512,300),(0,0,255),2)\n",
    "#cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,0,255),2)\n",
    "\n",
    "#How to create a rectangle on an image.if we've to create filled colored rectangle instaed of blank rectangle we can write cv2.rectangle(img,(120,80),(400,250),(0,0,255),cv2.FILLED)  \n",
    "cv2.rectangle(img,(120,80),(400,250),(0,0,128),2)\n",
    "\n",
    "# How to create circle\n",
    "#cv2.circle(img, (256,256),50,(0,255,0),3)\n",
    "\n",
    "#How to display text\n",
    "cv2.putText(img,\"Abhinay\",(120,60),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '346-3460443_machine-learning-course-near-me-machine-learning-logo.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the manual process of joining or stacking the images\n",
    "img = cv2.imread(path)\n",
    "imgGrey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img = cv2.resize(img,(100,100),None,0.8,0.8)\n",
    "imgGrey = cv2.resize(imgGrey,(100,100),None,0.8,0.8)\n",
    "\n",
    "imgGrey = cv2.cvtColor(imgGrey, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "hor = np.hstack((img,imgGrey))\n",
    "ver = np.vstack((img,imgGrey))\n",
    "\n",
    "cv2.imshow('Hor',hor)\n",
    "cv2.imshow('Ver',ver)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackimages(scale, imageArray):\n",
    "    rows = len(imageArray)\n",
    "    cols = len(imageArray[0])\n",
    "    rowsAvailable = isinstance(imageArray[0],list)\n",
    "    width = imageArray[0][0].shape[1]\n",
    "    height = imageArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for i in range(0,rows):\n",
    "            for j in range(0,cols):\n",
    "                if imageArray[i][j].shape[:2] == imageArray[0][0].shape[:2]:\n",
    "                    imageArray[i][j] = cv2.resize(imageArray[i][j],(0,0),None, scale, scale)\n",
    "                else:\n",
    "                    imageArray[i][j] = cv2.resize(imageArray[i][j],(width,height),None, scale,scale)\n",
    "                if len(imageArray[i][j]) == 2: imageArray[i][j] =  cv2.cvtColor(imageArray[i][j], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height,width,3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for i in range(0,rows):\n",
    "            hor[x] = np.hstack(imageArray[i])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for i in range(0, rows):\n",
    "            if imageArray[i].shape[:2] == imageArray[0].shape[:2]:\n",
    "                imageArray[i] = cv2.resize(imageArray[i], (0,0), None, scale, scale)\n",
    "            else:\n",
    "                imageArray[i] = cv2.resize(imageArray[i], (imageArray[0].shape[1],imageArray[0].shape[0]),None, scale, scale)\n",
    "            if len(imageArray[i]) == 2: imageArray[i] = cv2.cvtColor(imageArray[i], cv2.COLOR_GRAY2BGR)\n",
    "        hor = np.stack(imageArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '346-3460443_machine-learning-course-near-me-machine-learning-logo.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to join or stack multiple images\n",
    "\n",
    "img = cv2.imread(path)\n",
    "#imgGrey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#imgGrey = cv2.resize(imgGrey,(img.shape[1],img.shape[0]))\n",
    "#imgGrey = cv2.cvtColor(imgGrey,cv2.COLOR_GRAY2BGR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-x_mm3_2c/opencv/modules/core/src/array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8f9e24cdb30b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstackedImages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstackimages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stacked Images'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstackedImages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#cv2.imshow('Image',img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-x_mm3_2c/opencv/modules/core/src/array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n"
     ]
    }
   ],
   "source": [
    "stackedImages = stackimages(0.3,([img]))\n",
    "cv2.imshow('Stacked Images',stackedImages)\n",
    "\n",
    "\n",
    "#cv2.imshow('Image',img)\n",
    "#cv2.imshow('Image Grey',imgGrey)\n",
    "#cv2.imshow('Image Blur',imgBlur)\n",
    "#cv2.imshow('Image Canny',imgCanny)\n",
    "#cv2.imshow('Image Dialation',imgDialation)\n",
    "#cv2.imshow('Image Erode',imgErode)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.isOpened()\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameWidth = 640\n",
    "frameHeight = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stackimages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3883052031d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m    \u001b[1;31m# cv2.imshow('Video',imgGrey)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mstackedImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstackimages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimgGrey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stacked Images'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstackedImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stackimages' is not defined"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    cv2.imshow('Video',img)\n",
    "    \n",
    "    imgGrey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "   # cv2.imshow('Video',imgGrey)\n",
    "    \n",
    "    stackedImages = stackimages(0.8,([imgGrey]))\n",
    "    cv2.imshow('Stacked Images',stackedImages)\n",
    "\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  3.04166667,  5.08333333,  7.125     ,  9.16666667,\n",
       "       11.20833333, 13.25      , 15.29166667, 17.33333333, 19.375     ,\n",
       "       21.41666667, 23.45833333, 25.5       , 27.54166667, 29.58333333,\n",
       "       31.625     , 33.66666667, 35.70833333, 37.75      , 39.79166667,\n",
       "       41.83333333, 43.875     , 45.91666667, 47.95833333, 50.        ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.linspace(1,50,25)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247 247 247]\n"
     ]
    }
   ],
   "source": [
    "print(img[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(img[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(img[0][0].shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(img[0],list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-48fd3c67d0aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "print(img[0][0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[133  23]\n",
      " [  0   0]\n",
      " [  0   0]\n",
      " [  0   0]]\n",
      "[[133  23]\n",
      " [158  27]\n",
      " [  0   0]\n",
      " [  0   0]]\n",
      "[[133  23]\n",
      " [158  27]\n",
      " [145  50]\n",
      " [  0   0]]\n",
      "[[133  23]\n",
      " [158  27]\n",
      " [145  50]\n",
      " [205  45]]\n"
     ]
    }
   ],
   "source": [
    "circles = np.zeros((4,2),np.int)\n",
    "counter = 0\n",
    "\n",
    "def mouseClick(event,x,y,flags,params):\n",
    "    global counter\n",
    "    if event == cv2.EVENT_FLAG_LBUTTON:\n",
    "        circles[counter] = x,y\n",
    "        counter = counter + 1\n",
    "        print(circles)\n",
    "\n",
    "img = cv2.imread('four-kings-playing-cards-C5FAYX.jpg')\n",
    "while(True):\n",
    "    if counter == 4:\n",
    "        width, height = 250, 350\n",
    "        pts1 = np.float32([circles[0], circles[1], circles[2],circles[3]])\n",
    "        pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "        matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "        imgOutput = cv2.warpPerspective(img, matrix,(width,height))\n",
    "        cv2.imshow(\"Output Image\", imgOutput)\n",
    "        \n",
    "    for x in range(0,4):\n",
    "        cv2.circle(img,(circles[x][0],circles[x][1]),9,(0,0,255),cv2.FILLED)\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"Original Image\",img)\n",
    "    cv2.setMouseCallback(\"Original Image\",mouseClick)\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
